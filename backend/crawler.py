# backend/crawler.py
import requests
from bs4 import BeautifulSoup
import time
import random

# --- é…ç½®ä¼ªè£…å¤´ (é˜²æ­¢è¢«ç½‘ç«™æ‹¦æˆª) ---
HEADERS = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
}

def scrape_weibo_hot_search():
    """
    æŠ“å–å¾®åšçƒ­æœæ¦œ (https://s.weibo.com/top/summary)
    """
    url = "https://s.weibo.com/top/summary"
    try:
        # å‘é€è¯·æ±‚
        response = requests.get(url, headers=HEADERS, timeout=5)
        response.encoding = 'utf-8' # ç¡®ä¿ä¸­æ–‡ä¸ä¹±ç 
        
        # è§£æ HTML
        soup = BeautifulSoup(response.text, "html.parser")
        
        # å¾®åšçƒ­æœåœ¨ td class="td-02" ä¸‹çš„ a æ ‡ç­¾é‡Œ
        items = soup.select("td.td-02 > a")
        
        trends = []
        for item in items:
            title = item.get_text().strip()
            # è¿‡æ»¤æ‰ä¸€äº›å¹¿å‘Šæˆ–ç½®é¡¶çš„æ— æ•ˆå†…å®¹
            if not title or title == "javascript:void(0);":
                continue
            trends.append(f"ã€å¾®åšã€‘{title}")
            
        # åªå–å‰ 10 æ¡
        return trends[:10]
    
    except Exception as e:
        print(f"å¾®åšçˆ¬å–å¤±è´¥: {e}")
        return []

def scrape_baidu_hot_search():
    """
    æŠ“å–ç™¾åº¦çƒ­æœæ¦œ (https://top.baidu.com/board?tab=realtime)
    """
    url = "https://top.baidu.com/board?tab=realtime"
    try:
        response = requests.get(url, headers=HEADERS, timeout=5)
        response.encoding = 'utf-8'
        
        soup = BeautifulSoup(response.text, "html.parser")
        
        # ç™¾åº¦çƒ­æœæ ‡é¢˜é€šå¸¸åœ¨ class="c-single-text-ellipsis"
        items = soup.select(".c-single-text-ellipsis")
        
        trends = []
        for item in items:
            title = item.get_text().strip()
            if title:
                trends.append(f"ã€ç™¾åº¦ã€‘{title}")
        
        return trends[:10]
    
    except Exception as e:
        print(f"ç™¾åº¦çˆ¬å–å¤±è´¥: {e}")
        return []

# --- ç¼“å­˜æœºåˆ¶ (éå¸¸é‡è¦ï¼) ---
# é¿å…å‰ç«¯æ¯æ¬¡åˆ·æ–°éƒ½å»çˆ¬ä¸€æ¬¡ï¼ˆå®¹æ˜“è¢«å°IPï¼‰ï¼Œæˆ‘ä»¬è®¾ç½® 5 åˆ†é’Ÿç¼“å­˜
CACHE_DATA = {
    "trends": [],
    "last_updated": 0
}

def get_real_time_trends():
    """
    ç»Ÿä¸€å…¥å£ï¼šä¼˜å…ˆå¾®åšï¼Œå¤±è´¥è½¬ç™¾åº¦ï¼Œå¸¦ç¼“å­˜æœºåˆ¶
    """
    current_time = time.time()
    
    # 1. æ£€æŸ¥ç¼“å­˜æ˜¯å¦è¿‡æœŸ (300ç§’ = 5åˆ†é’Ÿ)
    if CACHE_DATA["trends"] and (current_time - CACHE_DATA["last_updated"] < 300):
        print("ğŸš€ ä½¿ç”¨ç¼“å­˜çƒ­ç‚¹æ•°æ®")
        return CACHE_DATA["trends"]
    
    print("ğŸŒ å¼€å§‹å®æ—¶æŠ“å–çƒ­ç‚¹...")
    
    # 2. å°è¯•æŠ“å–å¾®åš
    trends = scrape_weibo_hot_search()
    
    # 3. å¦‚æœå¾®åšæŒ‚äº†ï¼Œå°è¯•æŠ“å–ç™¾åº¦
    if not trends:
        print("âš ï¸ å¾®åšæŠ“å–ä¸ºç©ºï¼Œåˆ‡æ¢è‡³ç™¾åº¦æº...")
        trends = scrape_baidu_hot_search()
    
    # 4. æ›´æ–°ç¼“å­˜
    if trends:
        CACHE_DATA["trends"] = trends
        CACHE_DATA["last_updated"] = current_time
        return trends
    else:
        # 5. å¦‚æœå…¨æŒ‚äº†ï¼Œè¿”å›ç©ºåˆ—è¡¨ï¼ˆè®©è°ƒç”¨æ–¹å»ä½¿ç”¨ Mock æ•°æ®ï¼‰
        return []